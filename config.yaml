# CuliFeed Configuration
# Edit this file to customize your CuliFeed installation

# User Settings
user:
  timezone: "UTC"
  admin_user_id: "${CULIFEED_USER__ADMIN_USER_ID}"  # Optional: for admin commands

# Processing Settings
processing:
  daily_run_hour: 8                    # Hour of day to run processing (0-23)
  ai_provider: "groq"                  # Primary AI provider: gemini, groq, openai
  max_articles_per_topic: 5            # Maximum articles per topic per day
  batch_size: 10                       # Articles to process in one AI request
  parallel_feeds: 5                    # Concurrent RSS feed fetches
  max_content_length: 2000             # Max content length for AI analysis
  ai_relevance_threshold: 0.5          # Minimum AI relevance score to include article  
  ai_summary_threshold: 0.5            # Minimum AI relevance score to generate summary (Liberal mode)

# Cost Controls and Limits
limits:
  max_daily_api_calls: 950             # Stay under Gemini 1000 RPD free tier
  fallback_to_groq: true               # Use Groq when primary API exhausted
  fallback_to_keywords: true           # Use keyword-only when all APIs exhausted
  enable_usage_alerts: true            # Monitor free tier usage
  alert_threshold: 0.8                 # Alert at 80% of limits
  max_feed_errors: 10                  # Max errors before disabling feed
  request_timeout: 30                  # Request timeout in seconds

# Database Settings
database:
  path: "data/culifeed.db"             # SQLite database file location
  pool_size: 5                         # Connection pool size
  cleanup_days: 7                      # Days to keep old articles
  auto_vacuum: true                    # Automatic database maintenance
  backup_enabled: true                 # Enable automatic backups

# Logging Configuration
logging:
  level: "INFO"                        # DEBUG, INFO, WARNING, ERROR, CRITICAL
  file_path: "logs/culifeed.log"       # Log file location
  max_file_size_mb: 10                 # Max size before rotation
  backup_count: 5                      # Number of backup files
  structured_logging: false            # Use JSON structured logging
  console_logging: true                # Enable console output

# Telegram Bot Settings (Environment variables required)
telegram:
  bot_token: "${CULIFEED_TELEGRAM__BOT_TOKEN}"   # Required: Get from @BotFather
  admin_user_id: "${CULIFEED_USER__ADMIN_USER_ID}" # Optional: Admin user ID
  webhook_url: null                    # Optional: Webhook URL for updates
  max_retries: 3                       # Max retries for failed messages

# AI Provider Settings (Environment variables required)
ai:
  gemini_api_key: "${CULIFEED_AI__GEMINI_API_KEY}"  # Google Gemini API key (final fallback)
  groq_api_key: "${CULIFEED_AI__GROQ_API_KEY}"      # Groq API key (primary)
  huggingface_api_key: "${CULIFEED_AI__HUGGINGFACE_API_KEY}"  # HuggingFace API key (secondary)
  openrouter_api_key: "${CULIFEED_AI__OPENROUTER_API_KEY}"  # OpenRouter API key (tertiary)
  openai_api_key: "${CULIFEED_AI__OPENAI_API_KEY}"  # OpenAI API key (optional)
  
  # Multi-Model Configuration for Fallback
  gemini_models: ["gemini-2.5-flash", "gemini-2.5-flash-lite"]                        # Gemini models in priority order
  groq_models: ["llama-3.3-70b-versatile", "llama-3.1-8b-instant"]  # Groq models: premium → economy
  huggingface_models: ["facebook/bart-large-cnn", "facebook/bart-large", "sshleifer/distilbart-cnn-12-6", "google/pegasus-xsum", "cardiffnlp/twitter-roberta-base-sentiment-latest"]  # HuggingFace working models (confirmed)
  openrouter_models: ["meta-llama/llama-3.2-3b-instruct:free", "mistralai/mistral-7b-instruct:free"]  # OpenRouter FREE models (validated)
  openai_models: ["gpt-4o-mini"]                             # OpenAI models (future)
  
  # Legacy Model Configuration (backward compatibility)
  gemini_model: "gemini-1.5-flash"       # Primary Gemini model
  groq_model: "llama-3.3-70b-versatile"  # Primary Groq model
  huggingface_model: "facebook/bart-large-cnn"  # Primary HuggingFace model (confirmed working)
  openrouter_model: "meta-llama/llama-3.2-3b-instruct:free"  # Primary OpenRouter FREE model
  openai_model: "gpt-4o-mini"            # Primary OpenAI model
  
  temperature: 0.1                       # AI temperature (0.0-2.0)
  max_tokens: 500                        # Maximum tokens per response
  
  # Provider Priority Configuration (NEW - Dynamic AI provider ordering)
  provider_priority_profile: "cost_optimized"  # Options: cost_optimized, quality_first, balanced, custom
  custom_provider_order: []              # Custom provider order when using "custom" profile
  # Examples:
  # cost_optimized: groq → huggingface → openrouter → gemini → openai (default, free tiers first)
  # quality_first: openai → gemini → groq → huggingface → openrouter (premium models first)
  # balanced: gemini → groq → openai → huggingface → openrouter (mix of cost/quality)
  # custom: ["openai", "gemini"] (user-defined order, only specified providers)

# Trust validation settings removed for simplification

# Provider Quality Settings (New - AI provider confidence adjustment factors)
provider_quality:
  groq: 1.0                             # Premium quality provider (no adjustment)
  gemini: 1.0                           # Premium quality provider (no adjustment)
  openai: 1.0                           # Premium quality provider (no adjustment)
  huggingface: 0.70                     # Summarization models poor at relevance classification (30% reduction)
  openrouter: 0.70                      # Free tier limitations (30% reduction)
  keyword_backup: 0.45                  # Basic keyword matching (55% reduction)
  keyword_fallback: 0.45                # Basic keyword matching (55% reduction)

# Quality monitoring settings removed for simplification

# Filtering Settings (New - Pre-filter and processing threshold configuration)
filtering:
  # Pre-filter thresholds
  min_relevance_threshold: 0.1          # Minimum relevance score to pass pre-filtering
  
  # Phrase matching weights for keyword scoring
  exact_phrase_weight: 0.8              # Weight for exact phrase matches in keyword scoring
  partial_word_weight: 0.4              # Weight for partial word matches in multi-word keywords  
  single_word_tf_cap: 0.6               # Maximum score cap for single word TF (term frequency) scores
  keyword_match_bonus: 0.2              # Bonus multiplier for multiple keyword matches
  
  # Processing thresholds for hybrid fallback

  fallback_relevance_threshold: 0.3     # Minimum relevance score for keyword fallback processing
  fallback_confidence_cap: 0.6          # Maximum confidence score cap for hybrid fallback results
  
  # Quality scoring weights for articles
  title_quality_weight: 0.3             # Weight of title quality in overall article quality score
  content_quality_weight: 0.5           # Weight of content quality in overall article quality score
  recency_weight: 0.1                   # Weight of publication recency in overall article quality score
  url_quality_weight: 0.1               # Weight of URL quality in overall article quality score

# Smart Processing Settings (New - Confidence-based routing and cost optimization)
smart_processing:
  enabled: true                         # Re-enabled for testing with comprehensive test suite
  
  # Confidence-based routing thresholds
  high_confidence_threshold: 0.8        # Route directly without AI if confidence >= this value
  low_confidence_threshold: 0.6         # Route to keyword fallback if confidence >= this and score low
  
  # Routing decision thresholds
  definitely_relevant_threshold: 0.7    # Score threshold for "definitely relevant" routing
  definitely_irrelevant_threshold: 0.3  # Score threshold for "definitely irrelevant" routing
  
  # Performance and caching
  similarity_cache_enabled: true        # Enable basic content similarity caching
  max_cache_entries: 1000               # Maximum entries in similarity cache
  
  # Cost optimization settings
  ai_skip_rate_target: 0.4              # Target 40% AI request reduction through smart routing
  quality_assurance_sample_rate: 0.1    # Sample 10% of skipped articles for quality validation
  
  # Generic pattern classification settings
  generic_patterns_enabled: true        # Enable generic pattern classification for semantic penalties
  generic_patterns:                     # Categorized generic patterns - users can customize these
    update_feature:
      - "new feature"
      - "new features"
      - "latest feature"
      - "latest features"
      - "new update"
      - "new updates"
      - "latest update"
      - "latest updates"
      - "recent update"
      - "recent updates"
      - "update"
      - "updates"
      - "feature update"
      - "feature updates"
      - "new release"
      - "new releases"
      - "latest release"
      - "recent release"
      - "version update"
      - "upgrade"
      - "enhancement"
      - "enhancements"
      - "improvement"
      - "improvements"
    
    guide_tutorial:
      - "best practices"
      - "best practice"
      - "practices"
      - "tutorial"
      - "guide"
      - "documentation"
      - "announcement"
      - "announcements"
      - "how to"
      - "getting started"
      - "quick start"
      - "overview"
      - "introduction"
      - "tips"
      - "tips and tricks"
      - "tutorial guide"
      - "step by step"
      - "walkthrough"
      - "handbook"
      - "reference"
      - "cheat sheet"
    
    general_tech:
      - "development"
      - "coding"
      - "programming"
      - "algorithm"
      - "software"
      - "application"
      - "mobile app"
      - "web app"
      - "app development"
      - "technology"
      - "tech"
      - "digital"
      - "innovation"
      - "solution"
      - "solutions"
      - "framework"
      - "library"
      - "tool"
      - "tools"
      - "methodology"
      - "approach"
      - "strategy"
      - "implementation"
      - "architecture"
      - "design"
      - "pattern"
      - "patterns"
    
    cloud_aws:
      - "aws"
      - "amazon"
      - "cloud computing"
      - "cloud"
      - "cloud service"
      - "service"
      - "platform"
      - "infrastructure"
      - "deployment"
      - "hosting"
      - "server"
      - "serverless"
      - "microservices"
      - "devops"
      - "ci cd"
      - "automation"
      - "monitoring"
      - "logging"
      - "security"
      - "performance"
      - "scalability"
      - "reliability"
    
    business_industry:
      - "enterprise"
      - "business"
      - "industry"
      - "market"
      - "trends"
      - "analysis"
      - "report"
      - "survey"
      - "study"
      - "research"
      - "insights"
      - "data"
      - "analytics"
      - "metrics"
      - "kpi"
      - "roi"
      - "cost"
      - "pricing"
      - "budget"
      - "optimization"
    
    time_frequency:
      - "daily"
      - "weekly"
      - "monthly"
      - "quarterly"
      - "annual"
      - "regular"
      - "periodic"
      - "scheduled"
      - "routine"
      - "ongoing"
      - "continuous"
      - "real time"
      - "instant"
      - "immediate"
    
    quality_status:
      - "quality"
      - "testing"
      - "bug"
      - "bugs"
      - "issue"
      - "issues"
      - "problem"
      - "problems"
      - "fix"
      - "fixes"
      - "patch"
      - "patches"
      - "stable"
      - "beta"
      - "alpha"
      - "production"
      - "staging"
      - "maintenance"
      - "support"
      - "help"
      - "troubleshooting"
    
    descriptors:
      - "new"
      - "latest"
      - "recent"
      - "modern"
      - "advanced"
      - "simple"
      - "easy"
      - "quick"
      - "fast"
      - "efficient"
      - "powerful"
      - "flexible"
      - "comprehensive"
      - "complete"
      - "full"
      - "basic"
      - "essential"
      - "popular"
      - "trending"
      - "top"
      - "best"
      - "recommended"
    
    actions:
      - "learn"
      - "build"
      - "create"
      - "develop"
      - "deploy"
      - "manage"
      - "configure"
      - "setup"
      - "install"
      - "migrate"
      - "integrate"
      - "optimize"
      - "scale"
      - "monitor"
      - "secure"
      - "backup"
      - "restore"
      - "troubleshoot"
      - "debug"
      - "test"
      - "validate"

# Delivery Quality Settings (New - Message delivery quality thresholds and formatting)
delivery_quality:
  # Quality indicator thresholds for article confidence levels
  high_quality_threshold: 0.8           # Confidence threshold for high quality articles
  good_quality_threshold: 0.65          # Confidence threshold for good quality articles
  moderate_quality_threshold: 0.45      # Confidence threshold for moderate quality articles
  low_quality_threshold: 0.0            # Confidence threshold for low quality articles (anything above)
  
  # Content length limits - SINGLE SOURCE OF TRUTH
  max_summary_length: 700               # Maximum length for both AI summaries and content previews (prevents message overflow)
  
  # Reading time estimation for digest formatting
  reading_time_per_article: 0.5         # Estimated reading time per article in minutes
  min_reading_time: 1.0                 # Minimum reading time to display in minutes
  
  # Message formatting and delivery controls
  message_delay_seconds: 0.5            # Delay between sending multiple messages to avoid rate limiting
  content_break_threshold: 0.7          # Ratio threshold for smart content breaking at sentence boundaries

# Application Settings
app_name: "CuliFeed"
version: "1.0.0"
debug: false