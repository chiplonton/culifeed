# CuliFeed Configuration
# Edit this file to customize your CuliFeed installation

# User Settings
user:
  timezone: "UTC"
  admin_user_id: "${CULIFEED_USER__ADMIN_USER_ID}"  # Optional: for admin commands

# Processing Settings
processing:
  daily_run_hour: 8                    # Hour of day to run processing (0-23)
  ai_provider: "groq"                  # Primary AI provider: gemini, groq, openai
  max_articles_per_topic: 5            # Maximum articles per topic per day
  batch_size: 10                       # Articles to process in one AI request
  parallel_feeds: 5                    # Concurrent RSS feed fetches
  max_content_length: 2000             # Max content length for AI analysis
  ai_relevance_threshold: 0.5          # Minimum AI relevance score to include article  
  ai_summary_threshold: 0.5            # Minimum AI relevance score to generate summary (Liberal mode)

# Cost Controls and Limits
limits:
  max_daily_api_calls: 950             # Stay under Gemini 1000 RPD free tier
  fallback_to_groq: true               # Use Groq when primary API exhausted
  fallback_to_keywords: true           # Use keyword-only when all APIs exhausted
  enable_usage_alerts: true            # Monitor free tier usage
  alert_threshold: 0.8                 # Alert at 80% of limits
  max_feed_errors: 10                  # Max errors before disabling feed
  request_timeout: 30                  # Request timeout in seconds

# Database Settings
database:
  path: "data/culifeed.db"             # SQLite database file location
  pool_size: 5                         # Connection pool size
  cleanup_days: 7                      # Days to keep old articles
  auto_vacuum: true                    # Automatic database maintenance
  backup_enabled: true                 # Enable automatic backups

# Logging Configuration
logging:
  level: "INFO"                        # DEBUG, INFO, WARNING, ERROR, CRITICAL
  file_path: "logs/culifeed.log"       # Log file location
  max_file_size_mb: 10                 # Max size before rotation
  backup_count: 5                      # Number of backup files
  structured_logging: false            # Use JSON structured logging
  console_logging: true                # Enable console output

# Telegram Bot Settings (Environment variables required)
telegram:
  bot_token: "${CULIFEED_TELEGRAM__BOT_TOKEN}"   # Required: Get from @BotFather
  admin_user_id: "${CULIFEED_USER__ADMIN_USER_ID}" # Optional: Admin user ID
  webhook_url: null                    # Optional: Webhook URL for updates
  max_retries: 3                       # Max retries for failed messages

# AI Provider Settings (Environment variables required)
ai:
  gemini_api_key: "${CULIFEED_AI__GEMINI_API_KEY}"  # Google Gemini API key (final fallback)
  groq_api_key: "${CULIFEED_AI__GROQ_API_KEY}"      # Groq API key (primary)
  huggingface_api_key: "${CULIFEED_AI__HUGGINGFACE_API_KEY}"  # HuggingFace API key (secondary)
  openrouter_api_key: "${CULIFEED_AI__OPENROUTER_API_KEY}"  # OpenRouter API key (tertiary)
  openai_api_key: "${CULIFEED_AI__OPENAI_API_KEY}"  # OpenAI API key (optional)
  
  # Multi-Model Configuration for Fallback
  gemini_models: ["gemini-2.5-flash", "gemini-2.5-flash-lite"]                        # Gemini models in priority order
  groq_models: ["llama-3.3-70b-versatile", "llama-3.1-8b-instant"]  # Groq models: premium â†’ economy
  huggingface_models: ["facebook/bart-large-cnn", "facebook/bart-large", "sshleifer/distilbart-cnn-12-6", "google/pegasus-xsum", "cardiffnlp/twitter-roberta-base-sentiment-latest"]  # HuggingFace working models (confirmed)
  openrouter_models: ["meta-llama/llama-3.2-3b-instruct:free", "mistralai/mistral-7b-instruct:free"]  # OpenRouter FREE models (validated)
  openai_models: ["gpt-4o-mini"]                             # OpenAI models (future)
  
  # Legacy Model Configuration (backward compatibility)
  gemini_model: "gemini-1.5-flash"       # Primary Gemini model
  groq_model: "llama-3.3-70b-versatile"  # Primary Groq model
  huggingface_model: "facebook/bart-large-cnn"  # Primary HuggingFace model (confirmed working)
  openrouter_model: "meta-llama/llama-3.2-3b-instruct:free"  # Primary OpenRouter FREE model
  openai_model: "gpt-4o-mini"            # Primary OpenAI model
  
  temperature: 0.1                       # AI temperature (0.0-2.0)
  max_tokens: 500                        # Maximum tokens per response

# Trust Validation Settings (New - Phase 1 configurable thresholds)
trust_validation:
  # Core score difference thresholds
  max_score_difference: 0.7             # Max acceptable AI vs prefilter score difference (relaxed for Phase 1)
  warning_score_difference: 0.4         # Score difference threshold for warnings
  min_prefilter_for_high_ai: 0.05       # Min prefilter score for high AI scores
  max_ai_for_low_prefilter: 0.4         # Max AI score for very low prefilter scores
  
  # Confidence adjustment factors  
  confidence_penalty_factor: 0.85       # Confidence reduction for warnings (85%)
  confidence_failure_factor: 0.5        # Confidence reduction for failures (50%)
  
  # Critical mismatch detection thresholds
  critical_high_ai_threshold: 0.8       # AI score threshold for critical mismatch detection
  critical_low_prefilter_threshold: 0.1 # Prefilter threshold for critical mismatch detection
  critical_low_ai_threshold: 0.2        # Low AI score threshold for critical mismatch detection
  critical_high_prefilter_threshold: 0.7 # High prefilter threshold for critical mismatch detection
  
  # Suspicious score detection thresholds
  suspicious_high_ai_threshold: 0.7     # AI score threshold for suspicious high score detection
  suspicious_high_prefilter_threshold: 0.6 # Prefilter threshold for suspicious mismatch detection
  suspicious_low_ai_threshold: 0.3      # AI score threshold for suspicious low score detection
  
  # Batch consistency validation thresholds
  min_pass_rate: 0.7                    # Minimum validation pass rate (70%)
  max_fail_rate: 0.1                    # Maximum validation fail rate (10%)
  provider_fail_rate_threshold: 0.2     # Provider-specific fail rate threshold (20%)

# Provider Quality Settings (New - AI provider confidence adjustment factors)
provider_quality:
  groq: 1.0                             # Premium quality provider (no adjustment)
  gemini: 1.0                           # Premium quality provider (no adjustment)
  openai: 1.0                           # Premium quality provider (no adjustment)
  huggingface: 0.85                     # Good but summarization-focused (15% reduction)
  openrouter: 0.70                      # Free tier limitations (30% reduction)
  keyword_backup: 0.45                  # Basic keyword matching (55% reduction)
  keyword_fallback: 0.45                # Basic keyword matching (55% reduction)

# Quality Monitoring Settings (New - Alert thresholds for quality monitoring)
quality_monitoring:
  # Validation success rate monitoring
  validation_success_rate_min: 0.8      # Minimum validation success rate (80%)
  validation_success_rate_alert: 0.7    # Alert threshold for validation success rate (70%)
  
  # Processing performance monitoring  
  processing_time_max_seconds: 300      # Maximum processing time in seconds (5 minutes)
  processing_time_alert_seconds: 240    # Alert threshold for processing time (4 minutes)
  
  # Article quality monitoring
  article_quality_min: 0.6              # Minimum article quality score (60%)
  article_quality_alert: 0.5            # Alert threshold for article quality (50%)
  
  # Provider performance monitoring
  provider_success_rate_min: 0.9        # Minimum provider success rate (90%)
  provider_success_rate_alert: 0.8      # Alert threshold for provider success rate (80%)
  
  # API usage monitoring
  api_usage_alert_threshold: 0.85       # Alert when API usage exceeds 85%
  daily_api_calls_alert_threshold: 900  # Alert when daily API calls exceed 900
  
  # Error rate monitoring  
  error_rate_max: 0.05                  # Maximum acceptable error rate (5%)

# Filtering Settings (New - Pre-filter and processing threshold configuration)
filtering:
  # Pre-filter thresholds
  min_relevance_threshold: 0.1          # Minimum relevance score to pass pre-filtering
  
  # Phrase matching weights for keyword scoring
  exact_phrase_weight: 0.8              # Weight for exact phrase matches in keyword scoring
  partial_word_weight: 0.4              # Weight for partial word matches in multi-word keywords  
  single_word_tf_cap: 0.6               # Maximum score cap for single word TF (term frequency) scores
  keyword_match_bonus: 0.2              # Bonus multiplier for multiple keyword matches
  
  # Processing thresholds for hybrid fallback
  prefilter_minimum_threshold: 0.1      # Minimum prefilter score required for hybrid fallback processing
  fallback_relevance_threshold: 0.3     # Minimum relevance score for keyword fallback processing
  fallback_confidence_cap: 0.6          # Maximum confidence score cap for hybrid fallback results
  
  # Quality scoring weights for articles
  title_quality_weight: 0.3             # Weight of title quality in overall article quality score
  content_quality_weight: 0.5           # Weight of content quality in overall article quality score
  recency_weight: 0.1                   # Weight of publication recency in overall article quality score
  url_quality_weight: 0.1               # Weight of URL quality in overall article quality score

# Delivery Quality Settings (New - Message delivery quality thresholds and formatting)
delivery_quality:
  # Quality indicator thresholds for article confidence levels
  high_quality_threshold: 0.8           # Confidence threshold for high quality articles
  good_quality_threshold: 0.65          # Confidence threshold for good quality articles
  moderate_quality_threshold: 0.45      # Confidence threshold for moderate quality articles
  low_quality_threshold: 0.0            # Confidence threshold for low quality articles (anything above)
  
  # Reading time estimation for digest formatting
  reading_time_per_article: 0.5         # Estimated reading time per article in minutes
  min_reading_time: 1.0                 # Minimum reading time to display in minutes
  
  # Message formatting and delivery controls
  message_delay_seconds: 0.5            # Delay between sending multiple messages to avoid rate limiting
  content_break_threshold: 0.7          # Ratio threshold for smart content breaking at sentence boundaries

# Application Settings
app_name: "CuliFeed"
version: "1.0.0"
debug: false