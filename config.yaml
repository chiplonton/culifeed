# CuliFeed Configuration
# Edit this file to customize your CuliFeed installation

# User Settings
user:
  timezone: "UTC"
  admin_user_id: "${CULIFEED_USER__ADMIN_USER_ID}"  # Optional: for admin commands

# Processing Settings
processing:
  daily_run_hour: 8                    # Hour of day to run processing (0-23)
  ai_provider: "groq"                  # Primary AI provider: gemini, groq, openai
  max_articles_per_topic: 5            # Maximum articles per topic per day
  batch_size: 10                       # Articles to process in one AI request
  parallel_feeds: 5                    # Concurrent RSS feed fetches
  max_content_length: 2000             # Max content length for AI analysis
  ai_relevance_threshold: 0.5          # Minimum AI relevance score to include article  
  ai_summary_threshold: 0.5            # Minimum AI relevance score to generate summary (Liberal mode)

# Cost Controls and Limits
limits:
  max_daily_api_calls: 950             # Stay under Gemini 1000 RPD free tier
  fallback_to_groq: true               # Use Groq when primary API exhausted
  fallback_to_keywords: true           # Use keyword-only when all APIs exhausted
  enable_usage_alerts: true            # Monitor free tier usage
  alert_threshold: 0.8                 # Alert at 80% of limits
  max_feed_errors: 10                  # Max errors before disabling feed
  request_timeout: 30                  # Request timeout in seconds

# Database Settings
database:
  path: "data/culifeed.db"             # SQLite database file location
  pool_size: 5                         # Connection pool size
  cleanup_days: 7                      # Days to keep old articles
  auto_vacuum: true                    # Automatic database maintenance
  backup_enabled: true                 # Enable automatic backups

# Logging Configuration
logging:
  level: "INFO"                        # DEBUG, INFO, WARNING, ERROR, CRITICAL
  file_path: "logs/culifeed.log"       # Log file location
  max_file_size_mb: 10                 # Max size before rotation
  backup_count: 5                      # Number of backup files
  structured_logging: false            # Use JSON structured logging
  console_logging: true                # Enable console output

# Telegram Bot Settings (Environment variables required)
telegram:
  bot_token: "${CULIFEED_TELEGRAM__BOT_TOKEN}"   # Required: Get from @BotFather
  admin_user_id: "${CULIFEED_USER__ADMIN_USER_ID}" # Optional: Admin user ID
  webhook_url: null                    # Optional: Webhook URL for updates
  max_retries: 3                       # Max retries for failed messages

# AI Provider Settings (Environment variables required)
ai:
  gemini_api_key: "${CULIFEED_AI__GEMINI_API_KEY}"  # Google Gemini API key (final fallback)
  groq_api_key: "${CULIFEED_AI__GROQ_API_KEY}"      # Groq API key (primary)
  huggingface_api_key: "${CULIFEED_AI__HUGGINGFACE_API_KEY}"  # HuggingFace API key (secondary)
  openrouter_api_key: "${CULIFEED_AI__OPENROUTER_API_KEY}"  # OpenRouter API key (tertiary)
  openai_api_key: "${CULIFEED_AI__OPENAI_API_KEY}"  # OpenAI API key (optional)
  
  # Multi-Model Configuration for Fallback
  gemini_models: ["gemini-2.5-flash", "gemini-2.5-flash-lite"]                        # Gemini models in priority order
  groq_models: ["llama-3.3-70b-versatile", "llama-3.1-8b-instant"]  # Groq models: premium â†’ economy
  huggingface_models: ["microsoft/DialoGPT-medium", "google/flan-t5-large"]  # HuggingFace FREE models: high capacity (24K daily)
  openrouter_models: ["meta-llama/llama-3.2-3b-instruct:free", "mistralai/mistral-7b-instruct:free"]  # OpenRouter FREE models (validated)
  openai_models: ["gpt-4o-mini"]                             # OpenAI models (future)
  
  # Legacy Model Configuration (backward compatibility)
  gemini_model: "gemini-1.5-flash"       # Primary Gemini model
  groq_model: "llama-3.3-70b-versatile"  # Primary Groq model
  huggingface_model: "microsoft/DialoGPT-medium"  # Primary HuggingFace model
  openrouter_model: "meta-llama/llama-3.2-3b-instruct:free"  # Primary OpenRouter FREE model
  openai_model: "gpt-4o-mini"            # Primary OpenAI model
  
  temperature: 0.1                       # AI temperature (0.0-2.0)
  max_tokens: 500                        # Maximum tokens per response

# Application Settings
app_name: "CuliFeed"
version: "1.0.0"
debug: false